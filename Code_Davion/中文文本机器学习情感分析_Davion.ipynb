{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "21c63ba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>怎么现在都没有公告?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>603301超跌股</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>想问下公司送去武汉的几吨无菌纸巾是给谁用了，有效果没？这么长时间了，有效果应该上电视了吧，估...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;p class=\\</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>这个月在&lt;a href=\\</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  sentiment\n",
       "0                                         怎么现在都没有公告?          0\n",
       "1                                          603301超跌股         -1\n",
       "2  想问下公司送去武汉的几吨无菌纸巾是给谁用了，有效果没？这么长时间了，有效果应该上电视了吧，估...         -1\n",
       "3                                         <p class=\\          0\n",
       "4                                      这个月在<a href=\\          0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_excel('D:\\Davion\\data_test_train.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "429d76a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>cut_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>怎么现在都没有公告?</td>\n",
       "      <td>0</td>\n",
       "      <td>怎么 现在 都 没有 公告 ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>603301超跌股</td>\n",
       "      <td>-1</td>\n",
       "      <td>603301 超跌股</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>想问下公司送去武汉的几吨无菌纸巾是给谁用了，有效果没？这么长时间了，有效果应该上电视了吧，估...</td>\n",
       "      <td>-1</td>\n",
       "      <td>想 问下 公司 送 去 武汉 的 几吨 无菌 纸巾 是 给 谁 用 了 ， 有 效果 没 ？...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;p class=\\</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt; p   class = \\</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>这个月在&lt;a href=\\</td>\n",
       "      <td>0</td>\n",
       "      <td>这个 月 在 &lt; a   href = \\</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  sentiment  \\\n",
       "0                                         怎么现在都没有公告?          0   \n",
       "1                                          603301超跌股         -1   \n",
       "2  想问下公司送去武汉的几吨无菌纸巾是给谁用了，有效果没？这么长时间了，有效果应该上电视了吧，估...         -1   \n",
       "3                                         <p class=\\          0   \n",
       "4                                      这个月在<a href=\\          0   \n",
       "\n",
       "                                         cut_comment  \n",
       "0                                    怎么 现在 都 没有 公告 ?  \n",
       "1                                         603301 超跌股  \n",
       "2  想 问下 公司 送 去 武汉 的 几吨 无菌 纸巾 是 给 谁 用 了 ， 有 效果 没 ？...  \n",
       "3                                    < p   class = \\  \n",
       "4                              这个 月 在 < a   href = \\  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "\n",
    "def chinese_word_cut(mytext):\n",
    "    return \" \".join(jieba.cut(mytext))\n",
    "\n",
    "data['cut_comment'] = data.comment.apply(chinese_word_cut)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "089c6abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def get_custom_stopwords(stop_words_file):\n",
    "    with open(stop_words_file) as f:\n",
    "        stopwords = f.read()\n",
    "    stopwords_list = stopwords.split('\\n')\n",
    "    custom_stopwords_list = [i for i in stopwords_list]\n",
    "    return custom_stopwords_list\n",
    "\n",
    "stop_words_file = 'D:\\Davion\\哈工大停用词表.txt'\n",
    "stopwords = get_custom_stopwords(stop_words_file)\n",
    "\n",
    "vect = CountVectorizer(max_df = 0.8, \n",
    "                       min_df = 3, \n",
    "                       token_pattern=u'(?u)\\\\b[^\\\\d\\\\W]\\\\w+\\\\b', \n",
    "                       stop_words=frozenset(stopwords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "72456ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['cut_comment']\n",
    "y = data.sentiment\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "51a224dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:388: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['exp', 'lex', '①①', '①②', '①③', '①④', '①⑤', '①⑥', '①⑦', '①⑧', '①⑨', '①ａ', '①ｂ', '①ｃ', '①ｄ', '①ｅ', '①ｆ', '①ｇ', '①ｈ', '①ｉ', '①ｏ', '②①', '②②', '②③', '②④', '②⑤', '②⑥', '②⑦', '②⑧', '②⑩', '②ａ', '②ｂ', '②ｄ', '②ｅ', '②ｆ', '②ｇ', '②ｈ', '②ｉ', '②ｊ', '③①', '③⑩', '③ａ', '③ｂ', '③ｃ', '③ｄ', '③ｅ', '③ｆ', '③ｇ', '③ｈ', '④ａ', '④ｂ', '④ｃ', '④ｄ', '④ｅ', '⑤ａ', '⑤ｂ', '⑤ｄ', '⑤ｅ', '⑤ｆ', 'ｌｉ', 'ｚｘｆｉｔｌ'] not in stop_words.\n",
      "  warnings.warn('Your stop_words may be inconsistent with '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a股</th>\n",
       "      <th>biaoti</th>\n",
       "      <th>br</th>\n",
       "      <th>b股</th>\n",
       "      <th>class</th>\n",
       "      <th>cn</th>\n",
       "      <th>code</th>\n",
       "      <th>com</th>\n",
       "      <th>data</th>\n",
       "      <th>div</th>\n",
       "      <th>...</th>\n",
       "      <th>高速</th>\n",
       "      <th>高铁</th>\n",
       "      <th>鸭子</th>\n",
       "      <th>麻痹</th>\n",
       "      <th>黄山</th>\n",
       "      <th>黄金</th>\n",
       "      <th>黑马</th>\n",
       "      <th>鼓励</th>\n",
       "      <th>鼓掌</th>\n",
       "      <th>龙头</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2189 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   a股  biaoti  br  b股  class  cn  code  com  data  div  ...  高速  高铁  鸭子  麻痹  \\\n",
       "0   0       0   0   0      0   0     0    0     0    0  ...   0   0   0   0   \n",
       "1   0       0   0   0      0   0     0    0     0    0  ...   0   0   0   0   \n",
       "2   0       0   0   0      0   0     0    0     0    0  ...   0   0   0   0   \n",
       "3   1       0   0   0      0   0     0    0     0    0  ...   0   0   0   0   \n",
       "4   0       0   0   0      1   0     0    0     0    1  ...   0   0   0   0   \n",
       "\n",
       "   黄山  黄金  黑马  鼓励  鼓掌  龙头  \n",
       "0   0   0   0   0   0   0  \n",
       "1   0   0   0   0   0   0  \n",
       "2   0   0   0   0   0   0  \n",
       "3   0   0   0   0   0   0  \n",
       "4   0   0   0   0   0   0  \n",
       "\n",
       "[5 rows x 2189 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.DataFrame(vect.fit_transform(X_train).toarray(), columns=vect.get_feature_names())\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69fcb296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7173076923076923\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB(alpha=0.01)\n",
    "\n",
    "X_train_vect = vect.fit_transform(X_train)\n",
    "nb.fit(X_train_vect, y_train)\n",
    "train_score = nb.score(X_train_vect, y_train)\n",
    "\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07dcb842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.591025641025641\n"
     ]
    }
   ],
   "source": [
    "X_test_vect = vect.transform(X_test)\n",
    "print(nb.score(X_test_vect, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b81f53cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6576923076923077\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3) #,weights='distance'\n",
    "\n",
    "X_train_vect = vect.fit_transform(X_train)\n",
    "knn.fit(X_train_vect, y_train)\n",
    "train_score = knn.score(X_train_vect, y_train)\n",
    "\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d58e9ace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4782051282051282\n"
     ]
    }
   ],
   "source": [
    "X_test_vect = vect.transform(X_test)\n",
    "print(knn.score(X_test_vect, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af3d83af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4862179487179487\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel = 'rbf',probability = True)\n",
    "\n",
    "X_train_vect = vect.fit_transform(X_train)\n",
    "svm.fit(X_train_vect, y_train)\n",
    "train_score = svm.score(X_train_vect, y_train)\n",
    "\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbfd4d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4705128205128205\n"
     ]
    }
   ],
   "source": [
    "X_test_vect = vect.transform(X_test)\n",
    "print(svm.score(X_test_vect, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5da3546e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6676282051282051\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gbdt = GradientBoostingClassifier(n_estimators = 200)\n",
    "\n",
    "X_train_vect = vect.fit_transform(X_train)\n",
    "gbdt.fit(X_train_vect, y_train)\n",
    "train_score = gbdt.score(X_train_vect, y_train)\n",
    "\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47bf4e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.55\n"
     ]
    }
   ],
   "source": [
    "X_test_vect = vect.transform(X_test)\n",
    "print(gbdt.score(X_test_vect, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "993a782d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8910256410256411\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "ranfor = RandomForestClassifier(n_estimators = 8)\n",
    "\n",
    "X_train_vect = vect.fit_transform(X_train)\n",
    "ranfor.fit(X_train_vect, y_train)\n",
    "train_score = ranfor.score(X_train_vect, y_train)\n",
    "\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "26e22021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5743589743589743\n"
     ]
    }
   ],
   "source": [
    "X_test_vect = vect.transform(X_test)\n",
    "print(ranfor.score(X_test_vect, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8f0e3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9115384615384615\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "decitree = tree.DecisionTreeClassifier()\n",
    "\n",
    "X_train_vect = vect.fit_transform(X_train)\n",
    "decitree.fit(X_train_vect, y_train)\n",
    "train_score = decitree.score(X_train_vect, y_train)\n",
    "\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "140b754e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5628205128205128\n"
     ]
    }
   ],
   "source": [
    "X_test_vect = vect.transform(X_test)\n",
    "print(decitree.score(X_test_vect, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "58107e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7173076923076923\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB(alpha=0.01)\n",
    "\n",
    "X_train_vect = vect.fit_transform(X_train)\n",
    "nb.fit(X_train_vect, y_train)\n",
    "train_score = nb.score(X_train_vect, y_train)\n",
    "\n",
    "print(train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3e8b68d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.591025641025641\n"
     ]
    }
   ],
   "source": [
    "X_test_vect = vect.transform(X_test)\n",
    "print(nb.score(X_test_vect, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cd2e5251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>今天下个套</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.88追了，似乎得站岗了</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;p&gt;　　沉寂已久的钢铁板块近两日猛然拉升。是什么在催化钢铁股上行？业内人士认为，一方面，目...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>错过了最佳的机会~</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;div class=\\</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment\n",
       "0                                              今天下个套\n",
       "1                                      8.88追了，似乎得站岗了\n",
       "2  <p>　　沉寂已久的钢铁板块近两日猛然拉升。是什么在催化钢铁股上行？业内人士认为，一方面，目...\n",
       "3                                          错过了最佳的机会~\n",
       "4                                       <div class=\\"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"D:\\Davion\\data.xlsx\").astype(str)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "803af7b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>__</th>\n",
       "      <th>a0</th>\n",
       "      <th>a50</th>\n",
       "      <th>aa</th>\n",
       "      <th>aaa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>abc</th>\n",
       "      <th>about</th>\n",
       "      <th>admin</th>\n",
       "      <th>aec</th>\n",
       "      <th>...</th>\n",
       "      <th>龙年</th>\n",
       "      <th>龙抬头</th>\n",
       "      <th>龙溪</th>\n",
       "      <th>龙生</th>\n",
       "      <th>龙胎</th>\n",
       "      <th>龙虎榜</th>\n",
       "      <th>龙蟒</th>\n",
       "      <th>龙门客栈</th>\n",
       "      <th>龙飞</th>\n",
       "      <th>龟儿子</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19485 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   __  a0  a50  aa  aaa  aaaa  abc  about  admin  aec  ...  龙年  龙抬头  龙溪  龙生  \\\n",
       "0   0   0    0   0    0     0    0      0      0    0  ...   0    0   0   0   \n",
       "1   0   0    0   0    0     0    0      0      0    0  ...   0    0   0   0   \n",
       "2   0   0    0   0    0     0    0      0      0    0  ...   0    0   0   0   \n",
       "3   0   0    0   0    0     0    0      0      0    0  ...   0    0   0   0   \n",
       "4   0   0    0   0    0     0    0      0      0    0  ...   0    0   0   0   \n",
       "\n",
       "   龙胎  龙虎榜  龙蟒  龙门客栈  龙飞  龟儿子  \n",
       "0   0    0   0     0   0    0  \n",
       "1   0    0   0     0   0    0  \n",
       "2   0    0   0     0   0    0  \n",
       "3   0    0   0     0   0    0  \n",
       "4   0    0   0     0   0    0  \n",
       "\n",
       "[5 rows x 19485 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(\"D:\\Davion\\data.xlsx\").astype(str)\n",
    "data['cut_comment'] = data.comment.apply(chinese_word_cut)\n",
    "X=data['cut_comment']\n",
    "X_vec = vect.transform(X)\n",
    "\n",
    "nb_result = nb.predict(X_vec)\n",
    "data['nb_result'] = nb_result\n",
    "test = pd.DataFrame(vect.fit_transform(X).toarray(), columns=vect.get_feature_names())\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9652be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel(\"D:\\Davion\\data_result.xlsx\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
